# -*- coding: utf-8 -*-
"""Classificador de Desenvolvedor

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jHuvooHyw0-z__nktxXWs6w89oMjH5Ak
"""

import pandas as pd
import requests
import re
from bs4 import BeautifulSoup
from time import sleep

targets_for_text = ['Portal Fácil','ABO-MG','GOVBR TB','RKM SISTEMAS','Betha','GRP','RKM SISTEMAS E SERVIÇOS LTDA'
                    ,'Síntese Tecnologia e Informática','IPM Sistemas','3G Net Soluções Web','Codiub','Tecnologia Global Sistemas',
                    'ADPM','DEC Soluções Digitais','Instar Tecnologia','CONECT BR TECNOLOGIA LTDA.','Vitória Tecnologia Ltda','W8 Serviços e Tecnologia Web','Município Web','Masterix Sistemas']
targets_for_link = ['http://www.portalfacil.com.br','https://www.abominas.org.br/','https://rkms.com.br/','http://www.conam.com.br/']
targets_for_split = ['portaltp','betha','memory','portalcidadao','horusdm','siplanweb']

headers = {
    'Accept-Encoding': 'gzip, deflate, sdch',
    'Accept-Language': 'en-US,en;q=0.8',
    'Upgrade-Insecure-Requests': '1',
    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Cache-Control': 'max-age=0',
    'Connection': 'keep-alive',
}

def encontrar_provedor(pagina):
  lista = pagina.split(".")
  for x in lista:
    if x in targets_for_split:
      print(x)
      return
  for y in lista:
    lista2 = y.split('/')
  for z in lista2:
    if z in targets_for_split:
      print("grp")
      return
  max_retries = 1
  retries = max_retries
  while (retries):
    retries -= 1
    try:
      sleep(1)
      page = requests.get(pagina,headers=headers)
      soup = BeautifulSoup(page.content,"html5lib")
      for searched_word in targets_for_text:
        results = soup.body.find_all(string=re.compile('.*{0}.*'.format(searched_word)), recursive=True)
        if len(results) != 0:
            print(f'{searched_word.lower()}')
            return
      links = soup.findAll("a")
      for link in links:
        if link.get('href') in targets_for_link:
          print(link.get('href'))
          return
      print("N/A")
    except (requests.exceptions.ConnectionError, requests.exceptions.Timeout, requests.exceptions.TooManyRedirects, TimeoutError):
      print("Failed to connect to ", pagina, ". Attempt:", max_retries - retries, " of ", max_retries)
    else:
      break

dataset = pd.read_table("/content/links.tsv")
for link in dataset["links"]:
  encontrar_provedor(link);
